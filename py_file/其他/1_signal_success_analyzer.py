#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
===============================================================================
è„šæœ¬ 1ï¼ˆå†…å­˜å®‰å…¨ç‰ˆï¼‰ï¼š
    1_signal_success_analyzer_partitioned.py

ã€æ ¸å¿ƒèŒè´£ã€‘
    - ä» data/day/*.csv ä¸­æå–ã€Œä¿¡å·çº§æ ·æœ¬ã€
    - è®¡ç®—æœªæ¥ N æ—¥æ”¶ç›Š + æˆåŠŸæ ‡ç­¾
    - è¾“å‡ºä¸º Parquetï¼Œå¹¶æŒ‰ year åˆ†åŒºï¼ˆä¸º Walk-forward æœåŠ¡ï¼‰

ã€é‡è¦åŸåˆ™ã€‘
    âŒ ä¸è®­ç»ƒæ¨¡å‹
    âŒ ä¸åšé˜ˆå€¼åˆ¤æ–­
    âœ… åªç”Ÿæˆï¼šæ ·æœ¬ + ç‰¹å¾ + æ ‡ç­¾

ã€è¾“å‡ºç»“æ„ã€‘
    output/signal_samples_parquet/
        â”œâ”€â”€ year=2016/part-*.parquet
        â”œâ”€â”€ year=2017/part-*.parquet
        â””â”€â”€ ...

ã€ä¸ºä»€ä¹ˆè¦ year åˆ†åŒºã€‘
    ğŸ‘‰ è„šæœ¬ 2 åªéœ€è¯»å–ï¼šæŸä¸€å¹´ valid + å‰ N å¹´ train
    ğŸ‘‰ é¿å…ä¸€æ¬¡æ€§åŠ è½½åƒä¸‡è¡Œæ•°æ®
===============================================================================
"""

import os
import warnings
from datetime import datetime
from multiprocessing import Pool

import numpy as np
import pandas as pd
from tqdm import tqdm

from indicators import calculate_all_signals

warnings.simplefilter("ignore", category=FutureWarning)

# =============================================================================
# æ—¥å¿—å·¥å…·
# =============================================================================

def log(msg: str):
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{ts}] {msg}", flush=True)

# =============================================================================
# è·¯å¾„é…ç½®
# =============================================================================

PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(PROJECT_ROOT, "data", "day")

OUTPUT_DIR = os.path.join(PROJECT_ROOT, "output", "signal_samples_parquet")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# =============================================================================
# å‚æ•°åŒºï¼ˆå·¥ç¨‹å¯è°ƒï¼‰
# =============================================================================

MIN_BARS = 80            # æœ€å°‘å†å²Kçº¿
FUTURE_DAYS = 20         # æœªæ¥è§‚å¯Ÿçª—å£
GAIN_THRESHOLD = 5.0     # æˆåŠŸæ¶¨å¹…é˜ˆå€¼ï¼ˆ%ï¼‰
COOLDOWN = 5             # ä¿¡å·å†·å´æœŸï¼ˆäº¤æ˜“æ—¥ï¼‰

NUM_WORKERS = 12          # å¹¶è¡Œè¿›ç¨‹æ•°ï¼ˆ16G æ¨è 4~8ï¼‰
FLUSH_EVERY = 300        # å•è¿›ç¨‹ç´¯è®¡å¤šå°‘æ¡æ ·æœ¬åè½ç›˜

# =============================================================================
# ä¸­æ–‡åˆ—åæ˜ å°„
# =============================================================================

CN_COL_MAP = {
    "åç§°": "name",
    "æ—¥æœŸ": "date",
    "å¼€ç›˜": "open",
    "æ”¶ç›˜": "close",
    "æœ€é«˜": "high",
    "æœ€ä½": "low",
    "æˆäº¤é‡": "volume",
    "æˆäº¤é¢": "amount",
    "æŒ¯å¹…": "amplitude",
    "æ¶¨è·Œå¹…": "pct_chg",
    "æ¶¨è·Œé¢": "chg",
    "æ¢æ‰‹ç‡": "turnover",
}

# =============================================================================
# ç‰¹å¾åˆ—ï¼ˆâš  å¿…é¡»ä¸è„šæœ¬ 2 å®Œå…¨ä¸€è‡´ï¼‰
# =============================================================================

FEATURE_COLS = [
    "close", "volume", "MA13", "MA26",
    "six_veins_count", "banker", "retail", "accumulate",
    "pct_chg", "amplitude", "turnover",
    "macd_red", "kdj_red", "rsi_red", "bbi_red",
]

# =============================================================================
# å·¥å…·å‡½æ•°
# =============================================================================

def apply_cooldown(idxs, cooldown):
    """å¯¹ä¿¡å·ç´¢å¼•åº”ç”¨å†·å´æœŸï¼Œåªä¿ç•™é—´éš” >= cooldown çš„ç¬¬ä¸€ä¸ª"""
    keep, last = [], -9999
    for i in idxs:
        if i - last >= cooldown:
            keep.append(i)
            last = i
    return keep


def calc_future_gain(df: pd.DataFrame) -> pd.Series:
    """same-day ä¹°å…¥ï¼Œæœªæ¥ FUTURE_DAYS å†…æœ€å¤§æ¶¨å¹…"""
    future_high = (
        df["high"]
        .shift(-1)
        .rolling(FUTURE_DAYS, min_periods=FUTURE_DAYS)
        .max()
        .shift(-(FUTURE_DAYS - 1))
    )
    return (future_high - df["close"]) / df["close"] * 100

# =============================================================================
# å•è‚¡ç¥¨å¤„ç†ï¼ˆå­è¿›ç¨‹ï¼‰
# =============================================================================

def process_one(csv_path: str):
    try:
        df = pd.read_csv(csv_path)
        df = df.rename(columns={k: v for k, v in CN_COL_MAP.items() if k in df.columns})

        if "date" not in df.columns:
            return None

        df["date"] = pd.to_datetime(df["date"], errors="coerce")
        df = df.dropna(subset=["date"]).sort_values("date").reset_index(drop=True)

        if len(df) < MIN_BARS:
            return None

        # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡ & ä¿¡å·
        df = calculate_all_signals(df)

        # è‡ªåŠ¨è¯†åˆ«ä¹°ç‚¹ç±»ä¿¡å·
        signal_map = {}
        for col in df.columns:
            cl = col.lower()
            if "sell" in cl:
                continue

            if df[col].dtype == bool and df[col].any():
                signal_map[col] = df.index[df[col]].tolist()
            elif any(k in cl for k in ["buy", "six_veins", "combo"]):
                try:
                    idxs = df.index[df[col] > 0].tolist()
                    if idxs:
                        signal_map[col] = idxs
                except:
                    pass

        if not signal_map:
            return None

        df["future_gain_20d"] = calc_future_gain(df)
        df["success_20d"] = (df["future_gain_20d"] >= GAIN_THRESHOLD).astype("int8")

        stock = os.path.splitext(os.path.basename(csv_path))[0]
        name = df["name"].iloc[-1] if "name" in df.columns else ""

        records = []

        for sig, idxs in signal_map.items():
            idxs = apply_cooldown(idxs, COOLDOWN)
            for i in idxs:
                if pd.isna(df.at[i, "future_gain_20d"]):
                    continue

                rec = {
                    "stock": stock,
                    "name": name,
                    "signal": sig,
                    "date": df.at[i, "date"],
                    "year": int(df.at[i, "date"].year),
                    "entry_price": df.at[i, "close"],
                    "future_gain_20d": df.at[i, "future_gain_20d"],
                    "success_20d": df.at[i, "success_20d"],
                }

                for f in FEATURE_COLS:
                    rec[f] = df.at[i, f] if f in df.columns else np.nan

                records.append(rec)

        return pd.DataFrame(records) if records else None

    except Exception:
        return None

# =============================================================================
# ä¸»ç¨‹åº
# =============================================================================

def main():
    log("è„šæœ¬1å¯åŠ¨ï¼šç”Ÿæˆä¿¡å·æ ·æœ¬ï¼ˆyear åˆ†åŒºï¼‰")

    csvs = [
        os.path.join(r, f)
        for r, _, fs in os.walk(DATA_DIR)
        for f in fs if f.endswith(".csv")
    ]
    log(f"å‘ç° CSV æ•°é‡: {len(csvs)}")
    log(f"å¹¶è¡Œè¿›ç¨‹æ•°: {NUM_WORKERS}")

    buffer = []

    with Pool(NUM_WORKERS) as pool:
        for res in tqdm(
            pool.imap_unordered(process_one, csvs),
            total=len(csvs),
            desc="ç”Ÿæˆä¿¡å·æ ·æœ¬"
        ):
            if res is not None and not res.empty:
                buffer.append(res)

            if len(buffer) >= FLUSH_EVERY:
                flush_buffer(buffer)
                buffer.clear()

    if buffer:
        flush_buffer(buffer)

    log("è„šæœ¬1ç»“æŸ")


def flush_buffer(buffer):
    """å°† buffer ä¸­çš„æ•°æ®æŒ‰ year åˆ†åŒºå†™å…¥ parquet"""
    df = pd.concat(buffer, ignore_index=True)

    # é™å†…å­˜ï¼ˆéå¸¸å…³é”®ï¼‰
    for c in FEATURE_COLS:
        df[c] = df[c].astype("float32")

    df["success_20d"] = df["success_20d"].astype("int8")

    df.to_parquet(
        OUTPUT_DIR,
        partition_cols=["year"],
        index=False
    )

if __name__ == "__main__":
    main()
